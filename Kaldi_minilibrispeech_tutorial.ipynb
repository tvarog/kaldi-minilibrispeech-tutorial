{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaldi minilibrispeech tutorial",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "17BZnzr8f1dYRQ_c5Xk-NGnCsHvQUDieW",
      "authorship_tag": "ABX9TyP71+0FP2P2H0FAStnG2Zr6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvarog/kaldi-minilibrispeech-tutorial/blob/master/Kaldi_minilibrispeech_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHa_YbjxSdM-",
        "colab_type": "text"
      },
      "source": [
        "# Warsztaty z uczenia maszynowego A: problemy rozpoznawania mowy\n",
        "## Automatyczne Rozpoznawania Mowy (ASR) w pigułce - tutorial Kaldi\n",
        "###### 2020.05.15\n",
        "---\n",
        "###Marcin Sikora \n",
        "###(marcin.sikora at amu.edu.pl)\n",
        "---\n",
        "\n",
        "**Zaliczenia**:\n",
        "1. Obecności\n",
        "1. Zadania z 2-części warsztatów (2020-04-17, 2020-05-15)\n",
        "1. Ocena końcowa to średnia ocena z 2-części\n",
        "\n",
        "\n",
        "Termin zgłaszania zadań - do końca semestru.\n",
        "\n",
        "Skala ocen:\n",
        "- 3: zadanie 1.\n",
        "- 4: zadanie 1, niedokończone zadanie 2. \n",
        "- 5: zadanie 1, 2.\n",
        "\n",
        "**Agenda**:\n",
        "1. Przygotowanie środowiska\n",
        "1. Wprowadzenie teoretyczne\n",
        "1. Trening modelu minilibrispeech\n",
        "1. Zadania na zaliczenie\n",
        "\n",
        "**Przydatne linki/literatura**:\n",
        "\n",
        "- https://kaldi-asr.org/doc/kaldi_for_dummies.html\n",
        "- https://kaldi-asr.org/doc/data_prep.html (jak przygotować dane do treningu/testów)\n",
        "- https://github.com/tvarog/kaldi-minilibrispeech-tutorial (ten tutorial + zmodyfikowana recepta Kaldi\n",
        "- Dan Jurafsky, James H. Martin, Speech and Language Processing (3rd ed. draft), https://web.stanford.edu/~jurafsky/slp3/\n",
        "- Kaldi documentation, http://kaldi-asr.org/doc/ \n",
        "- Sanjeev Khudanpur, Dan Povey, Jan Trmal, Building Speech Recognition Systems with the Kaldi Toolkit, https://www.clsp.jhu.edu/wp-content/uploads/2016/06/Building-Speech-Recognition-Systems-with-the-Kaldi-Toolkit.pdf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T302l9bOcaOP",
        "colab_type": "text"
      },
      "source": [
        "![Kaldi](https://kaldi-asr.org/doc/KaldiTextAndLogoSmall.png)\n",
        "##Czym jest Kaldi?\n",
        "Kaldi to zestaw narzędzi open source napisany w C++, bashu, perlu i pythonie służący do budowania systemów rozpoznawania mowy i przetwarzania sygnałów, dostępny bezpłatnie na licencji Apache v2.0. Kaldi teoretycznie działa na Windowsie, ale w praktyce - nie polecam. Kaldi najlepiej czuje się na Linuksie, działa też po niewielkich modyfikacjach na OS X.\n",
        "\n",
        "Za pomocą Kaldi możemy:\n",
        "- zamienić sygnał mowy na cechy,\n",
        "- wytrenować i/lub zaadaptować modele akustyczne i językowe,\n",
        "- użyć wytrenowanych modeli do zdekodowania sygnału mowy,\n",
        "- i wiele innych.\n",
        "\n",
        "Na dzisiejszych zajęciach:\n",
        "- skonfigurujesz środowisko\n",
        "- skompilujesz Kaldi wraz z innymi niezbędnymi narzędziami,\n",
        "- przygotujesz dane do wytrenowania bardzo prostego modelu rozpoznawania mowy\n",
        "- wytrenujesz modele statystyczne - HMM-GMM oraz model neuronowy (chain)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBLmTAHacoJM",
        "colab_type": "text"
      },
      "source": [
        "Na początku sprawdźmy czy runtime do którego połączyliśmy się jest instancją GPU:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4dcrOJAAL69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi\n",
        "!tar xaf drive/My\\ Drive/Colab\\ Notebooks/kaldi.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvYDhgdhZi9Y",
        "colab_type": "text"
      },
      "source": [
        "Jeśli output polecenia nvidia-smi to:\n",
        "\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
        "\n",
        "```\n",
        "należy zmienić instancję na instancję GPU (`Menu Runtime -> Change runtime type -> GPU`). Uruchom polecenie raz jeszcze żeby potwierdzić, że jesteś na instancji GPU.\n",
        "\n",
        "Następnie sklonujmy repozytorium Kaldi:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG9QBsu7UpmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/kaldi-asr/kaldi.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqCWjXoEgYm6",
        "colab_type": "text"
      },
      "source": [
        "Aby zainstalować Kaldi, należy:\n",
        "- zainstalować/skompilować zewnętrzne narzędzia (`kaldi/tools/INSTALL`)\n",
        "- skompilować kod Kaldi (`kaldi/src/INSTALL`)\n",
        "\n",
        "Zacznijmy od narzędzi:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkFcCU0tA03f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat kaldi/tools/INSTALL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYIdgnyMiJFz",
        "colab_type": "text"
      },
      "source": [
        "Według instrukcji skrypt `kaldi/tools/extras/check_dependencies.sh` wylistuje pakiety które należy doinstalować, sprawdźmy więc:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljDgj7NsBJ4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaldi/tools/extras/check_dependencies.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am7HjbUViwl4",
        "colab_type": "text"
      },
      "source": [
        "Jak miło - dostaliśmy gotowe polecenia do instalacji wszystkich potrzebnych pakietów. Instalujemy:\n",
        "- `automake, autoconf` - narzędzia do automatycznego tworzenia plików Makefile\n",
        "- `sox` - bardzo użyteczne narzędzie do analizy i przetwarzania plików audio\n",
        "- `libtool` - narzędzie do linkowania binarek i bibliotek\n",
        "- `subversion` - inaczej SVN (poprzednik gita) \n",
        "- `mkl` - zestaw bibliotek do algebry numerycznej od Intela\n",
        "- Od siebie dodam jeszcze pakiet `flac` który będzie nam potrzebny do rozpakowania nagrań mowy w dalszej części tutoriala oraz `tree` do wyświetlania ładnie sformatowanych drzewek katalogów.\n",
        "\n",
        "Warning o złej wersji pythona można zignorować."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMgufyVCBmbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install automake autoconf sox libtool subversion flac tree\n",
        "!kaldi/tools/extras/install_mkl.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqEyI6Y8ka54",
        "colab_type": "text"
      },
      "source": [
        "Po zainstalowaniu pakietów z repozytoriów, resztę należy niestety skompilować. Trochę to potrwa. Zainstalujemy:\n",
        "- OpenFST - biblioteka do obsługi automatów skończenie stanowych\n",
        "- Sctk - narzędzie do obliczania wyników ewaluacji\n",
        "\n",
        "`-j2` spowoduje uruchomienie kompilacji w dwóch procesach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BoAxWUtDais",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/tools && make -j2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYKtzbSqo0Na",
        "colab_type": "text"
      },
      "source": [
        "Narzędzia są skompilowane, zaczynamy więc właściwą część instalacji. Sprawdźmy instrukcję:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbWZZruaF6w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat kaldi/src/INSTALL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzR_yOM8pzUY",
        "colab_type": "text"
      },
      "source": [
        "W pierwszej kolejności musimy wygenerować skrypty instalacyjne:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJCOf7akMoAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/src && ./configure --shared"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFF45OIXwIL-",
        "colab_type": "text"
      },
      "source": [
        "Po wygenerowaniu skryptów budujących Kaldi, uruchamiamy je. Znów - chwilę to potrwa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1WGeeQYMu5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/src && make depend -j2 && make -j2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8_KBW5BxAWA",
        "colab_type": "text"
      },
      "source": [
        "Instalacja Kaldi powinna być teraz gotowa do użycia. Sprawdźmy w takim razie co znajduje się w pakiecie:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHcR_st9xfo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tree -L 2 -d kaldi/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKCY09_GyqGS",
        "colab_type": "text"
      },
      "source": [
        "- `kaldi/tools` - zewnętrzne toole niezbędne do działania Kaldi\n",
        "- `kaldi/src` - “właściwy” kod Kaldi. Większość z programów ma jedną, dobrze określoną funkcję, co pozwala na łatwe składanie systemu ASR z różnych dostępnych klocków.\n",
        "- `kaldi/egs` - “recepty trenujące” powiązane z konkretnymi zadaniami. Receptę uruchamia się plikiem `run.sh`.\n",
        "- `kaldi/egs/$nazwa_recepty/$numer_recepty/steps` - uniwersalne skrypty wykonujące duże, konkretne zadania, np. zamianę plików wav na cechy MFCC, trening modelu monofonowego itp.\n",
        "- `kaldi/egs/$nazwa_recepty/$numer_recepty/local` - skrypty i pliki przygotowane pod konkretną receptę (np. przetwarzające dane wejściowe)\n",
        "\n",
        "Receptą którą wykorzystamy do wytrenowania prostego modelu rozpoznającego jezyk angielski jest recepta mini_librispeech. Jej zmodyfikowana pod Google Colab wersja, wraz z tymże notebookiem jest dostępna w repozytorium, które należy sklonować:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIxdJHL2h4P5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tvarog/kaldi-minilibrispeech-tutorial.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-GNGKHtEnYg",
        "colab_type": "text"
      },
      "source": [
        "Następnie wkopiujmy receptę bezpośrednio do katalogu `kaldi/egs`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgNk001vksYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -rvf kaldi-minilibrispeech-tutorial/mini_librispeech_tutorial/ kaldi/egs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOIrN8xgF0kY",
        "colab_type": "text"
      },
      "source": [
        "Jesteśmy gotowi do uruchomienia recepty. Receptę uruchamia się skryptem `run.sh`. Dla celów pokazowych została ona zmodyfikowana w taki sposób, żeby zatrzymać się po każdym wykonanym kroku. Konkretny krok wywołuje się parametrem `--stage $numer_kroku`.\n",
        "\n",
        "Przyjrzyjmy się jak wygląda pierwszy krok:\n",
        "```\n",
        "if [ $stage -eq -1 ]; then\n",
        "  for part in dev-clean-2 train-clean-5; do\n",
        "    local/download_and_untar.sh $data $data_url $part\n",
        "  done\n",
        "fi\n",
        "```\n",
        "W skrócie - ściągamy i rozpakowujemy korpus mowy trenujący i deweloperski. Jest to tylko niewielki wycinek korpusu librispeech, okrojony dla celów demonstracyjnych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOcc31X4k0Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L10T9mChIcd4",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy co wypakowaliśmy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bh-g1r8Kvdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tree kaldi/egs/mini_librispeech_tutorial/s5/corpus | head -n40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNIkbOdfUJTg",
        "colab_type": "text"
      },
      "source": [
        "W kolejnym kroku ściągniemy korpusy tekstowe:\n",
        "```\n",
        "if [ $stage -eq 0 ]; then\n",
        "  local/download_lm.sh $lm_url $data data/local/lm\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e7ZKOOslZHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcE4KcdIU0Tn",
        "colab_type": "text"
      },
      "source": [
        "Podejrzyjmy ściągnięte dane, najpierw model języka:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O28S71alVPtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zcat kaldi/egs/mini_librispeech_tutorial/s5/corpus//3-gram.arpa.gz | head -n40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuHR2PAJWQud",
        "colab_type": "text"
      },
      "source": [
        "Następnie prunowany (zmniejszony) model: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYViCoJqWX7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zcat kaldi/egs/mini_librispeech_tutorial/s5/corpus/3-gram.pruned.3e-7.arpa.gz | head -n40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRg4SQn5VoFJ",
        "colab_type": "text"
      },
      "source": [
        "Następnie leksykon:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mlagGAyVsMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n40 kaldi/egs/mini_librispeech_tutorial/s5/corpus/librispeech-lexicon.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-E3m6I-XANT",
        "colab_type": "text"
      },
      "source": [
        "W kolejnym kroku bierzemy surowe, ściągnięte dane i przygotowujemy je do wykorzystania w Kaldi:\n",
        "```\n",
        "if [ $stage -eq 1 ]; then\n",
        "  # format the data as Kaldi data directories\n",
        "  for part in dev-clean-2 train-clean-5; do\n",
        "    # use underscore-separated names in data directories.\n",
        "    local/data_prep.sh $data/LibriSpeech/$part data/$(echo $part | sed s/-/_/g)\n",
        "  done\n",
        "\n",
        "  # take only 100 first samples from dev_clean_2 to speed-up model evaluation\n",
        "  cp -rf data/dev_clean_2 data/dev_clean_2.bak\n",
        "  head -n100 data/dev_clean_2.bak/wav.scp > data/dev_clean_2/wav.scp\n",
        "  ./utils/fix_data_dir.sh data/dev_clean_2\n",
        "\n",
        "  local/prepare_dict.sh --stage 3 --nj $nj --cmd \"$train_cmd\" \\\n",
        "    data/local/lm data/local/lm data/local/dict_nosp\n",
        "\n",
        "  utils/prepare_lang.sh data/local/dict_nosp \\\n",
        "    \"<UNK>\" data/local/lang_tmp_nosp data/lang_nosp\n",
        "\n",
        "  local/format_lms.sh --src-dir data/lang_nosp data/local/lm\n",
        "  # Create ConstArpaLm format language model for full 3-gram and 4-gram LMs\n",
        "  utils/build_const_arpa_lm.sh data/local/lm/lm_tgmed.arpa.gz \\\n",
        "    data/lang_nosp data/lang_nosp_test_tgmed\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKOwF-ovlpdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9rjTRmTYghM",
        "colab_type": "text"
      },
      "source": [
        "Finalnie przygotowane dane znajdują się w katalogu `data`, sprawdźmy co leży w środku:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V08ge9xlY0wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tree kaldi/egs/mini_librispeech_tutorial/s5/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SHASwkkZJJX",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy najpierw korpus trenujący. W pliku `text` znajdują się tzw. referencje, czyli transkrypcje mowy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0so6Bn5bZMjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat kaldi/egs/mini_librispeech_tutorial/s5/data/train_clean_5/text | head -n20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fTnLhvvZhOS",
        "colab_type": "text"
      },
      "source": [
        "W pliku `wav.scp` znajdują się ścieżki do plików audio:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkgIiKDhZ7Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat kaldi/egs/mini_librispeech_tutorial/s5/data/train_clean_5/wav.scp | head -n20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t60PF_l2aDLC",
        "colab_type": "text"
      },
      "source": [
        "W pliku `spk2utt` znajdują się mappingi speaker -> ID pliku "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppibxCacasdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat kaldi/egs/mini_librispeech_tutorial/s5/data/train_clean_5/spk2utt | head -n20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLriBn18a3H6",
        "colab_type": "text"
      },
      "source": [
        "Odwrotny mapping znajduje się w pliku `utt2spk`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhEH1Kswa-uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat kaldi/egs/mini_librispeech_tutorial/s5/data/train_clean_5/utt2spk | head -n20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6PFH8rvbWHB",
        "colab_type": "text"
      },
      "source": [
        "Mapping speaker -> płeć znajduje się w `spk2gender`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbWFu23Fbecv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat kaldi/egs/mini_librispeech_tutorial/s5/data/train_clean_5/spk2gender | head -n20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5-ReR8bb0N7",
        "colab_type": "text"
      },
      "source": [
        "Dane fonetyczne znajdują się z kolei w `data/local/dict_nosp`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md8jJ6tNcKPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n20 kaldi/egs/mini_librispeech_tutorial/s5/data/local/dict_nosp/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2aNML0nc60s",
        "colab_type": "text"
      },
      "source": [
        "Kolejnym krokiem jest zamiana plików audio na cechy sygnału:\n",
        "```\n",
        "if [ $stage -eq 2 ]; then\n",
        "  mfccdir=mfcc\n",
        "\n",
        "  for part in dev_clean_2 train_clean_5; do\n",
        "    steps/make_mfcc.sh --cmd \"$train_cmd\" --nj $nj data/$part exp/make_mfcc/$part $mfccdir\n",
        "    steps/compute_cmvn_stats.sh data/$part exp/make_mfcc/$part $mfccdir\n",
        "  done\n",
        "\n",
        "  # Get the shortest 500 utterances first because those are more likely\n",
        "  # to have accurate alignments.\n",
        "  utils/subset_data_dir.sh --shortest data/train_clean_5 500 data/train_500short\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYayWdV-m2vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DznT6uW5ddHD",
        "colab_type": "text"
      },
      "source": [
        "Wygenerowane cechy MFCC znajdują się w katalogu `mfcc`, podejrzyjmy też logi w `exp/make_mfcc/` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0xrrT8Bdv5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l kaldi/egs/mini_librispeech_tutorial/s5/mfcc\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/make_mfcc/dev_clean_2/make_mfcc_dev_clean_2.1.log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fUBI_p8eqUA",
        "colab_type": "text"
      },
      "source": [
        "Mamy gotowe już wszystkie niezbędne do wytrenowania systemu dane:\n",
        "- cechy sygnału (czyli wejście do modelu akustycznego)\n",
        "- słownik fonetyczny (czyli połączenie wejścia do modelu językowego i wyjscia z modelu akustycznego)\n",
        "- model języka\n",
        "\n",
        "Zacznijmy od wytrenowania modelu monofonowego:\n",
        "```\n",
        "if [ $stage -eq 3 ]; then\n",
        "  steps/train_mono.sh --boost-silence 1.25 --nj $nj --cmd \"$train_cmd\" \\\n",
        "    data/train_500short data/lang_nosp exp/mono\n",
        "  (\n",
        "    utils/mkgraph.sh data/lang_nosp_test_tgsmall \\\n",
        "      exp/mono exp/mono/graph_nosp_tgsmall\n",
        "    for test in dev_clean_2; do\n",
        "      steps/decode.sh --nj $nj --cmd \"$decode_cmd\" exp/mono/graph_nosp_tgsmall \\\n",
        "        data/$test exp/mono/decode_nosp_tgsmall_$test\n",
        "    done\n",
        "  )\n",
        "\n",
        "  steps/align_si.sh --boost-silence 1.25 --nj $nj --cmd \"$train_cmd\" \\\n",
        "    data/train_clean_5 data/lang_nosp exp/mono exp/mono_ali_train_clean_5\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BXIUm6On984",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83cAL4LBfnsj",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy output z treningu:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68sNEuLGfp5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tree kaldi/egs/mini_librispeech_tutorial/s5/exp/mono/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMppMosehtzG",
        "colab_type": "text"
      },
      "source": [
        "Interesuje nas to jak radzi sobie wytrenowany model w praktyce. Zerknijmy na logi z dekodera i porównajmy wynik z referencjami z `data/dev_clean_2/text`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99cgaBqOh0ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n5 kaldi/egs/mini_librispeech_tutorial/s5/data/dev_clean_2/text\n",
        "!head -n15 kaldi/egs/mini_librispeech_tutorial/s5/exp/mono/decode_nosp_tgsmall_dev_clean_2/log/decode.1.log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytfTgSbBitfZ",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy też ile wynosi Word Error Rate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1HEzLIvSRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/mono/decode_nosp_tgsmall_dev_clean_2/wer_10_0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azeeaYf3jMC1",
        "colab_type": "text"
      },
      "source": [
        "Cóż, rozpoznajemy dobrze co drugie słowo. Nie najlepiej, ale pamiętajmy, że wytrenowaliśmy bardzo prosty model korzystając z bardzo małej ilości danych.\n",
        "\n",
        "Korzystając z modelu monofonowego, wytrenujmy lepszy model - model trifonowy:\n",
        "```\n",
        "if [ $stage -eq 4 ]; then\n",
        "  steps/train_deltas.sh --boost-silence 1.25 --cmd \"$train_cmd\" \\\n",
        "    2000 10000 data/train_clean_5 data/lang_nosp exp/mono_ali_train_clean_5 exp/tri1\n",
        "\n",
        "  # decode using the tri1 model\n",
        "  (\n",
        "    utils/mkgraph.sh data/lang_nosp_test_tgsmall \\\n",
        "      exp/tri1 exp/tri1/graph_nosp_tgsmall\n",
        "    for test in dev_clean_2; do\n",
        "      steps/decode.sh --nj $nj --cmd \"$decode_cmd\" exp/tri1/graph_nosp_tgsmall \\\n",
        "      data/$test exp/tri1/decode_nosp_tgsmall_$test\n",
        "      steps/lmrescore.sh --cmd \"$decode_cmd\" data/lang_nosp_test_{tgsmall,tgmed} \\\n",
        "        data/$test exp/tri1/decode_nosp_{tgsmall,tgmed}_$test\n",
        "      steps/lmrescore_const_arpa.sh \\\n",
        "        --cmd \"$decode_cmd\" data/lang_nosp_test_{tgsmall,tgmed} \\\n",
        "        data/$test exp/tri1/decode_nosp_{tgsmall,tgmed}_$test\n",
        "    done\n",
        "  )\n",
        "\n",
        "  steps/align_si.sh --nj $nj --cmd \"$train_cmd\" \\\n",
        "    data/train_clean_5 data/lang_nosp exp/tri1 exp/tri1_ali_train_clean_5\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTI0ffTEvnR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2lgN5nHjugY",
        "colab_type": "text"
      },
      "source": [
        "Tym razem sprawdzamy wytrenowany model akustyczny korzystając z małego i średniego modelu języka (tgsmall, tgmed):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o0IzxDAyKCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n5 kaldi/egs/mini_librispeech_tutorial/s5/data/dev_clean_2/text\n",
        "!head -n15 kaldi/egs/mini_librispeech_tutorial/s5/exp/tri1/decode_nosp_tgsmall_dev_clean_2/log/decode.1.log\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri1/decode_nosp_tgsmall_dev_clean_2/wer_10_0.0\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri1/decode_nosp_tgmed_dev_clean_2/wer_10_0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrUPDJP8lABL",
        "colab_type": "text"
      },
      "source": [
        "Jest dużo lepiej, ale wciąż kiepsko.\n",
        "\n",
        "Wytrenujmy kolejny model, model trifonowy z cechami zdekorelowanymi przy użyciu LDA:\n",
        "```\n",
        "if [ $stage -eq 5 ]; then\n",
        "  steps/train_lda_mllt.sh --cmd \"$train_cmd\" \\\n",
        "    --splice-opts \"--left-context=3 --right-context=3\" 2500 15000 \\\n",
        "    data/train_clean_5 data/lang_nosp exp/tri1_ali_train_clean_5 exp/tri2b\n",
        "\n",
        "  # decode using the LDA+MLLT model\n",
        "  (\n",
        "    utils/mkgraph.sh data/lang_nosp_test_tgsmall \\\n",
        "      exp/tri2b exp/tri2b/graph_nosp_tgsmall\n",
        "    for test in dev_clean_2; do\n",
        "      steps/decode.sh --nj $nj --cmd \"$decode_cmd\" exp/tri2b/graph_nosp_tgsmall \\\n",
        "        data/$test exp/tri2b/decode_nosp_tgsmall_$test\n",
        "      steps/lmrescore.sh --cmd \"$decode_cmd\" data/lang_nosp_test_{tgsmall,tgmed} \\\n",
        "        data/$test exp/tri2b/decode_nosp_{tgsmall,tgmed}_$test\n",
        "      steps/lmrescore_const_arpa.sh \\\n",
        "        --cmd \"$decode_cmd\" data/lang_nosp_test_{tgsmall,tgmed} \\\n",
        "        data/$test exp/tri2b/decode_nosp_{tgsmall,tgmed}_$test\n",
        "    done\n",
        "  )\n",
        "\n",
        "  # Align utts using the tri2b model\n",
        "  steps/align_si.sh  --nj $nj --cmd \"$train_cmd\" --use-graphs true \\\n",
        "    data/train_clean_5 data/lang_nosp exp/tri2b exp/tri2b_ali_train_clean_5\n",
        "fi\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIjZqD3-ym13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrOTsHeKl3tJ",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy wyniki:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a74v2OI-1y6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n5 kaldi/egs/mini_librispeech_tutorial/s5/data/dev_clean_2/text\n",
        "!head -n15 kaldi/egs/mini_librispeech_tutorial/s5/exp/tri2b/decode_nosp_tgsmall_dev_clean_2/log/decode.1.log\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri2b/decode_nosp_tgsmall_dev_clean_2/wer_10_0.0\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri2b/decode_nosp_tgmed_dev_clean_2/wer_10_0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f07i5CVumjXP",
        "colab_type": "text"
      },
      "source": [
        "Znów poprawa.\n",
        "\n",
        "Dodajmy dodatkową adaptację modelu per speaker (SAT):\n",
        "```\n",
        "if [ $stage -eq 6 ]; then\n",
        "  steps/train_sat.sh --cmd \"$train_cmd\" 2500 15000 \\\n",
        "    data/train_clean_5 data/lang_nosp exp/tri2b_ali_train_clean_5 exp/tri3b\n",
        "\n",
        "  # decode using the tri3b model\n",
        "  (\n",
        "    utils/mkgraph.sh data/lang_nosp_test_tgsmall \\\n",
        "      exp/tri3b exp/tri3b/graph_nosp_tgsmall\n",
        "    for test in dev_clean_2; do\n",
        "      steps/decode_fmllr.sh --nj $nj --cmd \"$decode_cmd\" \\\n",
        "        exp/tri3b/graph_nosp_tgsmall data/$test \\\n",
        "        exp/tri3b/decode_nosp_tgsmall_$test\n",
        "      steps/lmrescore.sh --cmd \"$decode_cmd\" data/lang_nosp_test_{tgsmall,tgmed} \\\n",
        "        data/$test exp/tri3b/decode_nosp_{tgsmall,tgmed}_$test\n",
        "      steps/lmrescore_const_arpa.sh \\\n",
        "        --cmd \"$decode_cmd\" data/lang_nosp_test_{tgsmall,tgmed} \\\n",
        "        data/$test exp/tri3b/decode_nosp_{tgsmall,tgmed}_$test\n",
        "    done\n",
        "  )\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiYM1aaD15ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1tKGAwZnl-R",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy wyniki:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_nYcuQp4kaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n5 kaldi/egs/mini_librispeech_tutorial/s5/data/dev_clean_2/text\n",
        "!head -n15 kaldi/egs/mini_librispeech_tutorial/s5/exp/tri3b/decode_nosp_tgsmall_dev_clean_2/log/decode.1.log\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri3b/decode_nosp_tgsmall_dev_clean_2/wer_10_0.0\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri3b/decode_nosp_tgmed_dev_clean_2/wer_10_0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knbXVPPIn8Lm",
        "colab_type": "text"
      },
      "source": [
        "Wyniki zaczynają być niezłe.\n",
        "\n",
        "Do tej pory zakładaliśmy, że różne wymowy tych samych słów mają identyczne prawdopodobieństwo wystąpienia. Nie jest to prawda. W poniższym kroku sprawdzimy jaki jest rozkład różnych wymów w korpusie trenującym.\n",
        "```\n",
        "if [ $stage -eq 7 ]; then\n",
        "  steps/get_prons.sh --cmd \"$train_cmd\" \\\n",
        "    data/train_clean_5 data/lang_nosp exp/tri3b\n",
        "  utils/dict_dir_add_pronprobs.sh --max-normalize true \\\n",
        "    data/local/dict_nosp \\\n",
        "    exp/tri3b/pron_counts_nowb.txt exp/tri3b/sil_counts_nowb.txt \\\n",
        "    exp/tri3b/pron_bigram_counts_nowb.txt data/local/dict\n",
        "\n",
        "  utils/prepare_lang.sh data/local/dict \\\n",
        "    \"<UNK>\" data/local/lang_tmp data/lang\n",
        "\n",
        "  local/format_lms.sh --src-dir data/lang data/local/lm\n",
        "\n",
        "  utils/build_const_arpa_lm.sh \\\n",
        "    data/local/lm/lm_tgmed.arpa.gz data/lang data/lang_test_tgmed\n",
        "\n",
        "  steps/align_fmllr.sh --nj $nj --cmd \"$train_cmd\" \\\n",
        "    data/train_clean_5 data/lang exp/tri3b exp/tri3b_ali_train_clean_5\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYWasP3s4tFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYYeF9gvpNf-",
        "colab_type": "text"
      },
      "source": [
        "Zerknijmy do zaktualizowanego słownika:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNa3KF1npQTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!grep \"^WITH \" kaldi/egs/mini_librispeech_tutorial/s5/data/local/dict/lexiconp.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Bz9ccMpR5C",
        "colab_type": "text"
      },
      "source": [
        "W następnym kroku wykorzystamy nowe informacje o słowniku i ponownie wytrenujemy ostatni model (SAT):\n",
        "```\n",
        "if [ $stage -eq 7 ]; then\n",
        "  steps/get_prons.sh --cmd \"$train_cmd\" \\\n",
        "    data/train_clean_5 data/lang_nosp exp/tri3b\n",
        "  utils/dict_dir_add_pronprobs.sh --max-normalize true \\\n",
        "    data/local/dict_nosp \\\n",
        "    exp/tri3b/pron_counts_nowb.txt exp/tri3b/sil_counts_nowb.txt \\\n",
        "    exp/tri3b/pron_bigram_counts_nowb.txt data/local/dict\n",
        "\n",
        "  utils/prepare_lang.sh data/local/dict \\\n",
        "    \"<UNK>\" data/local/lang_tmp data/lang\n",
        "\n",
        "  local/format_lms.sh --src-dir data/lang data/local/lm\n",
        "\n",
        "  utils/build_const_arpa_lm.sh \\\n",
        "    data/local/lm/lm_tgmed.arpa.gz data/lang data/lang_test_tgmed\n",
        "\n",
        "  steps/align_fmllr.sh --nj $nj --cmd \"$train_cmd\" \\\n",
        "    data/train_clean_5 data/lang exp/tri3b exp/tri3b_ali_train_clean_5\n",
        "fi\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iHSIPTu6D3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fHW-CUMpwRp",
        "colab_type": "text"
      },
      "source": [
        "Sprawdźmy wyniki:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWaWALKq77ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n5 kaldi/egs/mini_librispeech_tutorial/s5/data/dev_clean_2/text\n",
        "!head -n15 kaldi/egs/mini_librispeech_tutorial/s5/exp/tri3b/decode_tgsmall_dev_clean_2/log/decode.1.log\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri3b/decode_tgsmall_dev_clean_2/wer_10_0.0\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/tri3b/decode_tgmed_dev_clean_2/wer_10_0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftYmtv0ZpziO",
        "colab_type": "text"
      },
      "source": [
        "Jest już naprawdę dobrze (biorąc pod uwagę mikroskopijny zbiór uczący). Jeśli chcemy wytrenować lepszy model pozostają nam sieci neuronowe:\n",
        "```\n",
        "# Train a chain model\n",
        "if [ $stage -eq 9 ]; then\n",
        "  local/chain/run_tdnn.sh --stage 0\n",
        "fi\n",
        "```\n",
        "Dla zainteresowanych, opis sieci TDNN wykorzystanej w Kaldi: https://en.wikipedia.org/wiki/Time_delay_neural_network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3w45UaL8Y50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd kaldi/egs/mini_librispeech_tutorial/s5/ && bash run.sh --stage 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqBnHLvhuxVT",
        "colab_type": "text"
      },
      "source": [
        "Nie pozostaje nam nic innego niż obejrzeć wyniki:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGI2lQzpOjtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/chain/tdnn1h_sp/decode_tgsmall_dev_clean_2/wer_10_0.0\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/chain/tdnn1h_sp/decode_tgmed_dev_clean_2/wer_10_0.0\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/chain/tdnn1h_sp_online/decode_tgsmall_dev_clean_2/wer_10_0.0\n",
        "!cat kaldi/egs/mini_librispeech_tutorial/s5/exp/chain/tdnn1h_sp_online/decode_tgmed_dev_clean_2/wer_10_0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPc4jVpu1Xd",
        "colab_type": "text"
      },
      "source": [
        "Spadek liczby błędów jest znaczący, daleko nam jednak do jakości oferowanej przez komercyjne systemy ASR.\n",
        "\n",
        "---\n",
        "\n",
        "###Zadanie 1\n",
        "1. Znajdź nagranie z angielską mową.\n",
        "1. Skonwertuj nagranie do pliku wav, 16kHz, mono (np. w Audacity).\n",
        "1. Zuploaduj nagranie na instancję.\n",
        "1. Podmień `flac.*$` w ostatniej linijce `kaldi/egs/mini_librispeech_tutorial/s5/data/dev_clean_2/wav.scp` na ścieżkę do zuploadowanego pliku. Tip: żeby otrzymać pełną ścieżkę do pliku użyj polecenia `readlink -f PLIK`\n",
        "1. Podmień tekst w ostatniej linijce `kaldi/egs/mini_librispeech_tutorial/s5/data/dev_clean_2/wav.scp` na faktyczną zawartość nowego pliku\n",
        "1. Przegeneruj cechy sygnału - MFCC (stage 2)\n",
        "1. Uruchom dowolny trening (np. SAT) i sprawdź logach z dekodera co zostało rozpoznane. Wynik będzie prawdopodobnie na końcu logu `decode.2.log`\n",
        "1. Jako zaliczenie, wyślij plik `decode.2.log`\n",
        "\n",
        "###Zadanie 2\n",
        "1. Przygotuj maszynę wirtualną z Ubuntu 18.04.\n",
        "1. Przygotuj środowisko i skompiluj Kaldi, tak jak w omawianym dziś przykładzie.\n",
        "1. Wytrenuj model Kaldi na dużym zbiorze trenującym.\n",
        "1. Skorzystaj z recepty kaldi/egs/librispeech/s5.\n",
        "1. Jako zaliczenie, wyślij pliki raport porównujący wyniki na minilibrispeech i librispeech.\n",
        "\n",
        "Kilka ważnych uwag:\n",
        "- w pliku `cmd.sh` należy zmienić zawartość wszystkich zmiennych na `run.pl`\n",
        "- w pliku run.sh należy zmienić liczbę jobów przy każdym parametrze `--nj LICZBA` na liczbę rdzeni dostępnych na maszynie wirtualnej. Uwaga na pamięć!\n",
        "- w pliku run.sh należy zmienić wszystkie wystąpienia `tglarge` na `tgmed`. Na zwykłych PC model językowy `tglarge` może być zbyt duży do skompilowania.\n",
        "- tym razem skrypt run.sh nie zatrzymuje się po każdym kroku. Parametr `--stage LICZBA` kontroluje teraz tylko startowy krok.\n",
        "- skończ na stage 13. "
      ]
    }
  ]
}